{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 순환 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순환신경망(Recurrent Neural Network)은 지금까지 살펴본 네트워크와는 입력을 받아들이는 방식과 처리하는 방식에서 \n",
    "# 차이가 있다. RNN은 순서가 있는 데이터를 입력으로 받고 같은 네트워크를 이용해서 변화하는 입력에 대한 출력을 얻어낸다.\n",
    "# 순서가 있는 데이터로는 음악, 자연어, 날씨, 주가등 시간의 흐름에 따라 변화하고 그 변화가 의미를 갖는 데이터를 말한다.\n",
    "# 이번 장에서는 그중 가장 범용적으로 쓰이는 자연어 처리에 RNN을 사용하는 방법을 알아보기로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN은 일반적인 딥러닝 네트워크처럼 입력 X를 받아서 출력 Y를 반환하지만 추가로 되먹임 구조를 가진다는 차이가 있다.\n",
    "# 되먹임 구조란 어떤 레이어의 출력을 다시 입력으로 받는 구조를 말한다. RNN의 구조를 풀어보면 입력이 X1,X2,X3으로\n",
    "# 변할 때 같은 네트워크를 사용해서 출력인 Y1,Y2,Y3를 반환하고 있는데 꼭 염두에 둬야 할 점은 출력값이 다음 입력을 \n",
    "# 받을 때의 RNN 네트워크에도 동일하게 전달되고 있다는 것이다. 즉 RNN 네트워크는 처음에는 X1을 입력으로 받고 그다음\n",
    "# 에는 X2와 이전 단계 출력값인 Y1, 그다음에는 X3와 이전 단계 출력값인 Y2를 입력으로 받는다. 이과정에서 RNN 네트워크\n",
    "# 는 동일하게 사용된다.\n",
    "# RNN은 입력과 출력의 길이에 제한이 없다는 특징이 있다. 다양한 형태의 RNN으로는 \n",
    "# ONE TO MANY : Image Captioning,  MANY TO ONE : Sentiment Classification\n",
    "# MANY TO MANY : Machine Translation, Video Classification(Frame level)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimpleRNN 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN은 순서가 있는 데이터, 즉 변화하는 입력을 받기 때문에 각 단계에서 변화하는 입력에 대한 계산의 흐름을 파악하는\n",
    "# 것이 중요하다. Xt-1, Xt, Xt+1,...등은 SimpleRNN에 들어가는 입력을 나타내고 Ht-1, Ht, Ht+1등은 출력값들이다.\n",
    "# U는 입력에 곱해지는 가중치, W는 출력에 곱해지는 가중치이다. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 단계 t에서의 SimpleRNN레이어의 계산식 $tanh$는 실수 입력값을 받아 (-1, 1)사이의 출력값을 반환한다. \n",
    "##### $$H_{t} = tanh(U * X_{t} + W * H_{t-1})$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SimpleRNN레이어는 tf.keras에서 다음과 같이 생성할 수 있다.\n",
    "# units는 SimpleRNN레이어에 존재하는 뉴런의 수, return_sequences는 출력으로 시퀀스 전체를 출력할지 여부\n",
    "# rnn1 = tf.keras.layers.SimpleRNN(units=1, activation='tanh', return_sequences=True)\n",
    "# 간단한 예제로 시퀀스를 구성하는 앞쪽 4개의 숫자가 주어졌을 때 그다음에 올 숫자를 예측하는 간단한 \"시퀀스 예측 모델\"\n",
    "# 을 SimpleRNN레이어를 이용해 만들어 본다.(입력이 [1,2,3,4]일때, [5]를 예측하는 모델을 만드는 것이 목표이다.)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b18c970f1c267b2ae7de1f51c7b9ea29dc67f6c9f87d5b0ef47c4534e0830b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
